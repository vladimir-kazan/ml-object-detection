{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "MODEL_FILE_NAME = MODEL_NAME + '.tar.gz'\n",
    "DESTINATION_FOLDER = 'datasets'\n",
    "MODEL_FILE = os.path.join(DESTINATION_FOLDER, MODEL_FILE_NAME)\n",
    "\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = os.path.join(DESTINATION_FOLDER, MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join(DESTINATION_FOLDER, 'data', 'mscoco_label_map.pbtxt')\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-trained file if not exit locally\n",
    "if not os.path.isfile(MODEL_FILE) or \\\n",
    "    not os.path.isfile(os.path.join(DESTINATION_FOLDER, MODEL_NAME, 'frozen_inference_graph.pb')):\n",
    "        \n",
    "        opener = urllib.request.URLopener()\n",
    "        opener.retrieve(DOWNLOAD_BASE + MODEL_FILE_NAME, MODEL_FILE)\n",
    "        tar_file = tarfile.open(MODEL_FILE)\n",
    "        for file in tar_file.getmembers():\n",
    "            file_name = os.path.basename(file.name)\n",
    "            if 'frozen_inference_graph.pb' in file_name:\n",
    "                tar_file.extract(file, DESTINATION_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tensorflow trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane\n",
      "apple\n",
      "backpack\n",
      "banana\n",
      "baseball bat\n",
      "baseball glove\n",
      "bear\n",
      "bed\n",
      "bench\n",
      "bicycle\n",
      "bird\n",
      "boat\n",
      "book\n",
      "bottle\n",
      "bowl\n",
      "broccoli\n",
      "bus\n",
      "cake\n",
      "car\n",
      "carrot\n",
      "cat\n",
      "cell phone\n",
      "chair\n",
      "clock\n",
      "couch\n",
      "cow\n",
      "cup\n",
      "dining table\n",
      "dog\n",
      "donut\n",
      "elephant\n",
      "fire hydrant\n",
      "fork\n",
      "frisbee\n",
      "giraffe\n",
      "hair drier\n",
      "handbag\n",
      "horse\n",
      "hot dog\n",
      "keyboard\n",
      "kite\n",
      "knife\n",
      "laptop\n",
      "microwave\n",
      "motorcycle\n",
      "mouse\n",
      "orange\n",
      "oven\n",
      "parking meter\n",
      "person\n",
      "pizza\n",
      "potted plant\n",
      "refrigerator\n",
      "remote\n",
      "sandwich\n",
      "scissors\n",
      "sheep\n",
      "sink\n",
      "skateboard\n",
      "skis\n",
      "snowboard\n",
      "spoon\n",
      "sports ball\n",
      "stop sign\n",
      "suitcase\n",
      "surfboard\n",
      "teddy bear\n",
      "tennis racket\n",
      "tie\n",
      "toaster\n",
      "toilet\n",
      "toothbrush\n",
      "traffic light\n",
      "train\n",
      "truck\n",
      "tv\n",
      "umbrella\n",
      "vase\n",
      "wine glass\n",
      "zebra\n"
     ]
    }
   ],
   "source": [
    "from google.protobuf import text_format\n",
    "from protos import string_int_label_map_pb2\n",
    "\n",
    "label_map = string_int_label_map_pb2.StringIntLabelMap()\n",
    "with tf.gfile.GFile(PATH_TO_LABELS, 'r') as fid:\n",
    "    label_map_string = fid.read()\n",
    "    text_format.Merge(label_map_string, label_map)\n",
    "    \n",
    "\n",
    "label_dict = { item.id: item.display_name for item in label_map.item }\n",
    "# label_dict = {}\n",
    "# for item in label_map.item:\n",
    "#     label_dict[item.id] = item.display_name\n",
    "\n",
    "# print('\\n'.join(item[1] for item in sorted(label_dict.items(), key=lambda tup: tup[1])))\n",
    "print('\\n'.join(item.display_name for item in sorted(label_map.item, key=lambda k: k.display_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = './img/image1.jpg'\n",
    "img2 = './img/image2.jpg'\n",
    "img3 = './img/image3.jpg'\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        # Definite input and output Tensors for detection_graph\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "        image = Image.open(img3)\n",
    "        image_np = load_image_into_numpy_array(image)\n",
    "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "        (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablity = 98.58% that this is a train\n",
      "Probablity = 15.29% that this is a person\n",
      "[ 0.40593365  0.1493234   0.74471927  0.8904143 ]\n",
      "[ 0.66618496  0.19311416  0.68574136  0.20529506]\n"
     ]
    }
   ],
   "source": [
    "scores = np.squeeze(scores)\n",
    "classes = np.squeeze(classes).astype(np.int32)\n",
    "boxes = np.squeeze(boxes)\n",
    "print('Probablity = {0:.2f}% that this is a {1}'.format(scores[0] * 100, label_dict[classes[0]]))\n",
    "print('Probablity = {0:.2f}% that this is a {1}'.format(scores[1] * 100, label_dict[classes[1]]))\n",
    "print(boxes[0])\n",
    "print(boxes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'box': {'h': 0.8904143, 'w': 0.74471927, 'x': 0.40593365, 'y': 0.1493234},\n",
       " 'label': 'train',\n",
       " 'probability': 0.985750675201416}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (np.vectorize(label_dict.get)(classes))\n",
    "coord_labels = ['x', 'y', 'w', 'h']\n",
    "\n",
    "def box_to_dict(box):\n",
    "    return dict(zip(coord_labels, box))\n",
    "\n",
    "boxes_dict = np.apply_along_axis(box_to_dict, 1, boxes)\n",
    "\n",
    "result_labels = [ 'label', 'probability', 'box']\n",
    "\n",
    "def result_to_dict(row):\n",
    "    return dict(zip(result_labels, row))\n",
    "\n",
    "result = np.apply_along_axis(result_to_dict, 1, np.c_[labels, scores, boxes_dict])\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
